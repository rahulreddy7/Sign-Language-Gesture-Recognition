{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre_processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze2lK9UXlxLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e87e54cf-d9d7-4c2c-b23f-4df78158d3a6"
      },
      "source": [
        "#sqs poll\n",
        "import boto3\n",
        "import json\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np # linear algebra # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.models import model_from_json\n",
        "import statistics \n",
        "from statistics import mode "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAQWaugX5vvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "1ee6c111-ddec-4c66-8721-d06d1fe55fcb"
      },
      "source": [
        "!python -m pip install tensorflow-gpu==1.11.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/52/01438b81806765936eee690709edc2a975472c4e9d8d465a01840869c691/tensorflow_gpu-1.11.0-cp36-cp36m-manylinux1_x86_64.whl (258.8MB)\n",
            "\u001b[K     |████████████████████████████████| 258.8MB 49kB/s \n",
            "\u001b[?25hCollecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (1.28.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (1.18.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (3.10.0)\n",
            "Collecting tensorboard<1.12.0,>=1.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/2f/4d788919b1feef04624d63ed6ea45a49d1d1c834199ec50716edb5d310f4/tensorboard-1.11.0-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.11.0) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.5->tensorflow-gpu==1.11.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu==1.11.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu==1.11.0) (3.2.1)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement setuptools>=41.2, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc4 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.7.2 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: setuptools, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: setuptools 46.1.3\n",
            "    Uninstalling setuptools-46.1.3:\n",
            "      Successfully uninstalled setuptools-46.1.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "Successfully installed setuptools-39.1.0 tensorboard-1.11.0 tensorflow-gpu-1.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUhUbeh96AA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f951a65-ab8a-4bd4-ec0d-1905fdb0b201"
      },
      "source": [
        "cd /content/drive/My Drive/MC project/webinst/videos/tfjs-to-tf"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MC project/webinst/videos/tfjs-to-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMX5Phgd6C4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "63afaaea-a63f-4047-be00-6a5eaedcaee7"
      },
      "source": [
        "pip install . --no-deps"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/drive/My Drive/MC project/webinst/videos/tfjs-to-tf\n",
            "Building wheels for collected packages: tfjs-graph-converter\n",
            "  Building wheel for tfjs-graph-converter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tfjs-graph-converter: filename=tfjs_graph_converter-1.0.0-cp36-none-any.whl size=20277 sha256=7eec7dfef2aab4d18f4206e64a0cd420c40131e406154e87fe843602359838b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/d9/f4/4856730920807c20534a710d519e449079cf1c5c4710f64b9f\n",
            "Successfully built tfjs-graph-converter\n",
            "Installing collected packages: tfjs-graph-converter\n",
            "Successfully installed tfjs-graph-converter-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q4LcEZX7Ab1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6432810f-9e05-4f21-e808-4673e1b0849c"
      },
      "source": [
        "ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'ASL alphabet video_team'\u001b[0m/   \u001b[01;34mfinger_Spelling_model\u001b[0m/   \u001b[01;34mworking\u001b[0m/\n",
            "\u001b[01;34m'ASL alphabetvideo_team'\u001b[0m/    \u001b[01;34mwebinst\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVEf3echj9sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "region_name = 'us-east-1'\n",
        "queue_name = 'mcqueue'\n",
        "max_queue_messages = 1\n",
        "message_bodies = []\n",
        "aws_access_key_id = 'AKIAJ7HUDAMTZBQ7L74A'\n",
        "aws_secret_access_key = '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'\n",
        "sqs = boto3.resource('sqs', region_name=region_name,aws_access_key_id=aws_access_key_id,aws_secret_access_key=aws_secret_access_key)\n",
        "queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
        "while True:\n",
        "  messages_to_delete = []\n",
        "  for message in queue.receive_messages(MaxNumberOfMessages=max_queue_messages):\n",
        "      # process message body\n",
        "      body = json.loads(message.body)\n",
        "      message_bodies.append(body)\n",
        "      # add message to delete\n",
        "      messages_to_delete.append({\n",
        "          'Id': message.message_id,\n",
        "          'ReceiptHandle': message.receipt_handle\n",
        "      })\n",
        "      filetodown = body[\"Records\"][0][\"s3\"][\"object\"][\"key\"]\n",
        "      #download the video\n",
        "      #frameextractors\n",
        "      print(filetodown)\n",
        "      s3_client = boto3.client('s3',\n",
        "                         aws_access_key_id=aws_access_key_id,\n",
        "                         aws_secret_access_key= aws_secret_access_key)\n",
        "      response = s3_client.list_objects(Bucket=\"mcrequests\", Prefix=\"\")\n",
        "      for file in response['Contents']:\n",
        "        name = file['Key'].rsplit('/', 1)\n",
        "        print(name)\n",
        "        if name[0] == filetodown:\n",
        "          print(\"once\")\n",
        "          s3_client.download_file(Bucket=\"mcrequests\", Key=file['Key'], Filename='/content/drive/My Drive/MC project/working/videos/frames/sav.mp4')\n",
        "          #call frame extractor\n",
        "          frameextract()\n",
        "          posenet()\n",
        "          segmentation()\n",
        "          testdir = cropimages()\n",
        "          result = cnnmodel(testdir)\n",
        "          print(result)\n",
        "          getresult(result)\n",
        "          \n",
        "\n",
        "  print(messages_to_delete)\n",
        "  # if you don't receive any notifications the\n",
        "      # messages_to_delete list will be empty\n",
        "  if len(messages_to_delete) == 0:\n",
        "      break\n",
        "  # delete messages to remove them from SQS queue\n",
        "  # handle any errors\n",
        "  else:\n",
        "      delete_response = queue.delete_messages(Entries=messages_to_delete)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOV-rdLB74D5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "1a2b093a-0acb-4566-defd-db335a089cfc"
      },
      "source": [
        "frameextract()\n",
        "posenet()\n",
        "segmentation()\n",
        "testdir = cropimages()\n",
        "result = cnnmodel(testdir)\n",
        "print(result)\n",
        "getresult(result)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frame extraction started\n",
            "/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A\n",
            "frame extraction done\n",
            "Posenet started\n",
            "Posenet Completed\n",
            "[23.0, 24.0, 29.0, 30.0]\n",
            "cropping started\n",
            "0\n",
            "23.png\n",
            "0\n",
            "24.png\n",
            "0\n",
            "29.png\n",
            "0\n",
            "30.png\n",
            "cropping done\n",
            "cnn model started\n",
            "cnn model done\n",
            "[4 0 0 0]\n",
            "The results are\n",
            "[4 0 0 0]\n",
            "The highest occuring\n",
            "0\n",
            "pushing into s3\n",
            "s3 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czTRCVumkEho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#frame extractor\n",
        "def frameextract():\n",
        "  print(\"frame extraction started\")\n",
        "  path_to_video_files = \"/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu\"\n",
        "  path_to_frames = path_to_video_files + '/frames/'\n",
        "  path_to_video_files = path_to_video_files + '/'\n",
        "  video_files = os.listdir(path_to_video_files)\n",
        "  os.mkdir(path_to_frames)\n",
        "  for file in video_files:\n",
        "      video = cv2.VideoCapture(path_to_video_files + file)\n",
        "      flip = False\n",
        "      count = 0\n",
        "      success = 1\n",
        "      arr_img = []\n",
        "      # If such a directory doesn't exist, creates one and stores its Images\n",
        "      if not os.path.isdir(path_to_frames + os.path.splitext(file)[0] + \"/\"):\n",
        "          os.mkdir(path_to_frames + os.path.splitext(file)[0])\n",
        "          new_path = path_to_frames + os.path.splitext(file)[0]\n",
        "          print(new_path)\n",
        "          while success:\n",
        "              success, image = video.read()\n",
        "              # Frames when generated are getting rotated clockwise by above method, so correcting it\n",
        "              #print(success)\n",
        "              if success:\n",
        "                  if flip:\n",
        "                      print(\"flip\")\n",
        "                      image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "                  arr_img.append(image)\n",
        "                  #print(count)\n",
        "                  count += 1\n",
        "          # Sub sampling the number of frames\n",
        "          # numbers = sorted(random.sample(range(len(arr_img)), 45))\n",
        "          #print(len(arr_img))\n",
        "          #cv2.imshow('x',arr_img[-1])\n",
        "          #cv2.waitKey()\n",
        "          count = 0\n",
        "          for i in range(len(arr_img)):\n",
        "              cv2.imwrite(new_path + \"/%d.png\" % count, arr_img[i])\n",
        "              count += 1\n",
        "  print(\"frame extraction done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTr0--rfkG1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#posenet\n",
        "import os\n",
        "def posenet():\n",
        "  print(\"Posenet started\")\n",
        "  os.system(\"!python /content/drive/My\\ Drive/MC\\ project/webinst/videos/posenet-pytorch-master/image_demo.py --model 101 --image_dir /content/drive/My\\ Drive/MC\\ project/ASL\\ alphabet\\ video_team/Madhu/frames/A\")\n",
        "  shutil.copyfile('/content/drive/My Drive/MC project/working/key_points.csv', '/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/key_points.csv')\n",
        "  print(\"Posenet Completed\")\n",
        "#posenet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvawNvK02PXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to csv\n",
        "def convert_to_csv():\n",
        "    path_to_video = \"/content/drive/My Drive/MC project/working/videos/frames/key_points\"\n",
        "    columns = ['score_overall', 'nose_score', 'nose_x', 'nose_y', 'leftEye_score', 'leftEye_x', 'leftEye_y',\n",
        "               'rightEye_score', 'rightEye_x', 'rightEye_y', 'leftEar_score', 'leftEar_x', 'leftEar_y',\n",
        "               'rightEar_score', 'rightEar_x', 'rightEar_y', 'leftShoulder_score', 'leftShoulder_x', 'leftShoulder_y',\n",
        "               'rightShoulder_score', 'rightShoulder_x', 'rightShoulder_y', 'leftElbow_score', 'leftElbow_x',\n",
        "               'leftElbow_y', 'rightElbow_score', 'rightElbow_x', 'rightElbow_y', 'leftWrist_score', 'leftWrist_x',\n",
        "               'leftWrist_y', 'rightWrist_score', 'rightWrist_x', 'rightWrist_y', 'leftHip_score', 'leftHip_x',\n",
        "               'leftHip_y', 'rightHip_score', 'rightHip_x', 'rightHip_y', 'leftKnee_score', 'leftKnee_x', 'leftKnee_y',\n",
        "               'rightKnee_score', 'rightKnee_x', 'rightKnee_y', 'leftAnkle_score', 'leftAnkle_x', 'leftAnkle_y',\n",
        "               'rightAnkle_score', 'rightAnkle_x', 'rightAnkle_y']\n",
        "    data = json.loads(open(path_to_video + '.json', 'r').read())\n",
        "    csv_data = np.zeros((len(data), len(columns)))\n",
        "    for i in range(csv_data.shape[0]):\n",
        "        one = []\n",
        "        one.append(data[i]['score'])\n",
        "        for obj in data[i]['keypoints']:\n",
        "            one.append(obj['score'])\n",
        "            one.append(obj['position']['x'])\n",
        "            one.append(obj['position']['y'])\n",
        "        csv_data[i] = np.array(one)\n",
        "    pd.DataFrame(csv_data, columns=columns).to_csv(path_to_video + '.csv', index_label='Frames#')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIGeNrVRHkOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52e92331-0c97-4f92-a04a-13b2eba99b0f"
      },
      "source": [
        "cd /content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq8dUMe7kIXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#segmentation\n",
        "def segmentation():\n",
        "  df1 = pd.read_csv(\"/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/key_points.csv\")\n",
        "  df1 = df1[[\"Frames#\",\"rightWrist_y\"]]\n",
        "  x = 0\n",
        "  init = 0\n",
        "  flag = 0\n",
        "  listofframes = []\n",
        "  for index, row in df1.iterrows():\n",
        "    if flag == 0:\n",
        "      #get the decimal and integer part\n",
        "      dec = math.modf(row['rightWrist_y'])\n",
        "      #get the integer part\n",
        "      init = (int(dec[1]))\n",
        "      flag = 1\n",
        "    else:\n",
        "      #print(row['Frames#'], math.modf(row['rightWrist_y']))\n",
        "      dec = math.modf(row['rightWrist_y'])\n",
        "      #print(int(dec[1]))\n",
        "      if x == int(dec[1]) and x < init - 100:\n",
        "        #print(row['Frames#'], math.modf(row['rightWrist_y']))\n",
        "        listofframes.append(row['Frames#'])\n",
        "      x = int(dec[1])\n",
        "\n",
        "  print(listofframes)\n",
        "\n",
        "  ele = 1\n",
        "  #flag_two = 0\n",
        "  #flag_create = 0\n",
        "  count_frames = 0\n",
        "  filen = '/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output/'\n",
        "  if (os.path.isdir(filen)) == False:\n",
        "    os.mkdir(filen)\n",
        "  while ele < len(listofframes):\n",
        "    if(listofframes[ele] - listofframes[ele - 1] < 10):\n",
        "      if (os.path.isdir(filen + str(count_frames)+'/')) == False:\n",
        "        #create a directory and push it\n",
        "        os.mkdir(filen + str(count_frames)+'/')\n",
        "        shutil.copyfile('/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/' + str(int(listofframes[ele - 1])) + '.png', '/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output/'+str(count_frames)+'/' + str(int(listofframes[ele - 1])) + '.png')\n",
        "        #flag_two = 1\n",
        "      else:\n",
        "        shutil.copyfile('/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/' + str(int(listofframes[ele - 1])) + '.png', '/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output/'+str(count_frames)+'/' + str(int(listofframes[ele - 1])) + '.png')\n",
        "    else:\n",
        "      shutil.copyfile('/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/' + str(int(listofframes[ele - 1])) + '.png', '/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output/'+str(count_frames)+'/' + str(int(listofframes[ele - 1])) + '.png')\n",
        "      #flag_two = 0\n",
        "      count_frames = count_frames + 1\n",
        "    ele = ele + 1\n",
        "  shutil.copyfile('/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/' + str(int(listofframes[ele - 1])) + '.png', '/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output/'+str(count_frames)+'/' + str(int(listofframes[ele - 1])) + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvKXfAL09dXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb8b4dc7-4a52-4b1b-e30e-d29be9263fc9"
      },
      "source": [
        "segmentation()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[23.0, 24.0, 29.0, 30.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwfGbj_BkL0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#crop\n",
        "import cv2\n",
        "def cropimages():\n",
        "  print(\"cropping started\")\n",
        "  for folder in os.listdir('/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output'):\n",
        "    for image in os.listdir('/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output/'+folder):\n",
        "      print(folder)\n",
        "      df1 = pd.read_csv(\"/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/key_points.csv\")\n",
        "      df1 = df1[[\"Frames#\",\"rightWrist_y\"]]\n",
        "      for index, row in df1.iterrows():\n",
        "        if(str(index) == str(image.split('.')[0])):\n",
        "          print(image)\n",
        "      #print(id(0) == id(image.split('.')[0]))\n",
        "      image = '/content/drive/My Drive/MC project/ASL alphabet video_team/Madhu/frames/A/output/'+folder +'/'+image\n",
        "      img = cv2.imread(image)\n",
        "      #print(img)\n",
        "      crop_img = img[631-300:631+50, 425-50:425+250]\n",
        "      cv2.imwrite(image, crop_img)  \n",
        "      #cv2.imshow(\"cropped\", crop_img)\n",
        "      cv2.waitKey(0)\n",
        "  print(\"cropping done\")\n",
        "  return '/content/drive/My Drive/MC project/ASL alphabetvideo_team/Madhu/frames/A/output/'+folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdlEa9MU9p9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "be6849e8-05de-4c04-a3ce-73198acc5804"
      },
      "source": [
        "cropimages()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cropping started\n",
            "0\n",
            "23.png\n",
            "0\n",
            "24.png\n",
            "0\n",
            "29.png\n",
            "0\n",
            "30.png\n",
            "cropping done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/MC project/ASL alphabetvideo_team/Madhu/frames/A/output/0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyfAwDAKkMmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cnn\n",
        "def cnnmodel(test_dir):\n",
        "  test_dir = '/content/drive/My Drive/MC project/ASL alphabetvideo_team/Madhu/frames/A/output/0'\n",
        "  print(\"cnn model started\")\n",
        "  result = []\n",
        "  images=[]\n",
        "  size = 64,64\n",
        "  #count = 0\n",
        "  # for folder in os.listdir(test_dir):\n",
        "  #     #images=[]\n",
        "  for image in os.listdir(test_dir):\n",
        "      temp_img = cv2.imread(test_dir + '/' + image)\n",
        "      temp_img = cv2.resize(temp_img, size)\n",
        "      images.append(temp_img)\n",
        "      #print(type(images))\n",
        "      #print(images)\n",
        "      #print(len(images))\n",
        "      #count = count + 1\n",
        "      #print(count)\n",
        "  images = np.array(images)\n",
        "  images = images.astype('float32')/255.0\n",
        "  json_file = open('/content/drive/My Drive/MC project/working/videos/keypoints/model.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  loaded_model = model_from_json(loaded_model_json)\n",
        "  # load weights into new model\n",
        "  loaded_model.load_weights(\"/content/drive/My Drive/MC project/working/videos/keypoints/model.h5\")\n",
        "  loaded_model.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])\n",
        "  #print(loaded_model.summary())\n",
        "  v = loaded_model.predict_classes(images)\n",
        "  print(\"cnn model done\")\n",
        "  return v\n",
        "      #images = []\n",
        "  #new_model = model.load_weights('cnn.h5')\n",
        "  #predictions = new_model.predict_classes(images)\n",
        "  #print(predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTlz2vil95Eg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "3bc4e782-4bea-4373-f93e-d7a06c71db5f"
      },
      "source": [
        "getoutput = cnnmodel(\"x\")\n",
        "getresult(getoutput)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cnn model started\n",
            "cnn model done\n",
            "The results are\n",
            "[4 0 0 0]\n",
            "The highest occuring\n",
            "0\n",
            "pushing into s3\n",
            "s3 done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0hJ5fCHkOuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting result \n",
        "def getresult(result):\n",
        "  print(\"The results are\")\n",
        "  print(result)\n",
        "  sendoutput = []\n",
        "  #print(getresult_i)\n",
        "  freq = mode(result)\n",
        "  print(\"The highest occuring\")\n",
        "  print(freq)\n",
        "  sendoutput.append(freq)\n",
        "  #pushing into s3\n",
        "  print(\"pushing into s3\")\n",
        "  aws_access_key_id = 'AKIAJ7HUDAMTZBQ7L74A'\n",
        "  aws_secret_access_key = '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'\n",
        "  with open(\"/content/drive/My Drive/MC project/working/videos/text/file.txt\", \"w\") as output:\n",
        "      output.write(str(sendoutput))\n",
        "  s3_client = boto3.client('s3',aws_access_key_id=aws_access_key_id,aws_secret_access_key= aws_secret_access_key)\n",
        "  s3_client.upload_file('/content/drive/My Drive/MC project/working/videos/text/file.txt', 'mcoutputreq', 'testfordemo.txt')\n",
        "  print(\"s3 done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDeSHqqLlNqq",
        "colab_type": "code",
        "outputId": "f724f034-83e8-44f1-98a3-0c4ae59d7fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chiTeI3hl81n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}